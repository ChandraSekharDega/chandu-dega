{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Designing game AI with Reinforcement learning"]},{"cell_type":"code","execution_count":17,"metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2023-11-03T09:55:49.887280Z","iopub.status.busy":"2023-11-03T09:55:49.886733Z","iopub.status.idle":"2023-11-03T09:55:59.498082Z","shell.execute_reply":"2023-11-03T09:55:59.496840Z","shell.execute_reply.started":"2023-11-03T09:55:49.887232Z"},"id":"A2tg-PH3-bfM","outputId":"6d81da1b-4760-43cc-8050-aafb182a5fe6","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting kaggle-environments\n","  Using cached kaggle_environments-1.14.3-py2.py3-none-any.whl (1.3 MB)\n","Collecting Flask>=1.1.2\n","  Using cached flask-3.0.0-py3-none-any.whl (99 kB)\n","Collecting gymnasium==0.29.0\n","  Using cached gymnasium-0.29.0-py3-none-any.whl (953 kB)\n","Collecting jsonschema>=3.0.1\n","  Using cached jsonschema-4.19.2-py3-none-any.whl (83 kB)\n","Requirement already satisfied: numpy>=1.19.5 in c:\\users\\chand\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kaggle-environments) (1.26.1)\n","Collecting pettingzoo==1.24.0\n","  Using cached pettingzoo-1.24.0-py3-none-any.whl (840 kB)\n","Collecting requests>=2.25.1\n","  Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n","Collecting scipy>=1.11.2\n","  Using cached scipy-1.11.3-cp311-cp311-win_amd64.whl (44.1 MB)\n","Collecting shimmy>=1.2.1\n","  Using cached Shimmy-1.3.0-py3-none-any.whl (37 kB)\n","Collecting stable-baselines3==2.1.0\n","  Using cached stable_baselines3-2.1.0-py3-none-any.whl (178 kB)\n","Collecting transformers>=4.33.1\n","  Using cached transformers-4.35.0-py3-none-any.whl (7.9 MB)\n","Collecting vec-noise>=1.1.4\n","  Using cached vec_noise-1.1.4.zip (134 kB)\n","  Preparing metadata (setup.py): started\n","  Preparing metadata (setup.py): finished with status 'done'\n","Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\chand\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gymnasium==0.29.0->kaggle-environments) (3.0.0)\n","Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\chand\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gymnasium==0.29.0->kaggle-environments) (4.8.0)\n","Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\chand\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gymnasium==0.29.0->kaggle-environments) (0.0.4)\n","Collecting torch>=1.13\n","  Using cached torch-2.1.0-cp311-cp311-win_amd64.whl (192.3 MB)\n","Collecting pandas\n","  Using cached pandas-2.1.2-cp311-cp311-win_amd64.whl (10.6 MB)\n","Collecting matplotlib\n","  Using cached matplotlib-3.8.1-cp311-cp311-win_amd64.whl (7.6 MB)\n","Requirement already satisfied: Werkzeug>=3.0.0 in c:\\users\\chand\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from Flask>=1.1.2->kaggle-environments) (3.0.1)\n","Collecting Jinja2>=3.1.2\n","  Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB)\n","Requirement already satisfied: itsdangerous>=2.1.2 in c:\\users\\chand\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from Flask>=1.1.2->kaggle-environments) (2.1.2)\n","Requirement already satisfied: click>=8.1.3 in c:\\users\\chand\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from Flask>=1.1.2->kaggle-environments) (8.1.7)\n","Requirement already satisfied: blinker>=1.6.2 in c:\\users\\chand\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from Flask>=1.1.2->kaggle-environments) (1.7.0)\n","Requirement already satisfied: attrs>=22.2.0 in c:\\users\\chand\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=3.0.1->kaggle-environments) (23.1.0)\n","Collecting jsonschema-specifications>=2023.03.6\n","  Using cached jsonschema_specifications-2023.7.1-py3-none-any.whl (17 kB)\n","Collecting referencing>=0.28.4\n","  Using cached referencing-0.30.2-py3-none-any.whl (25 kB)\n","Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\chand\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=3.0.1->kaggle-environments) (0.12.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\chand\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.25.1->kaggle-environments) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\chand\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.25.1->kaggle-environments) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\chand\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.25.1->kaggle-environments) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\chand\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.25.1->kaggle-environments) (2023.7.22)\n","Requirement already satisfied: filelock in c:\\users\\chand\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers>=4.33.1->kaggle-environments) (3.13.1)\n","Collecting huggingface-hub<1.0,>=0.16.4\n","  Using cached huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n","Requirement already satisfied: packaging>=20.0 in c:\\users\\chand\\appdata\\roaming\\python\\python311\\site-packages (from transformers>=4.33.1->kaggle-environments) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in c:\\users\\chand\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers>=4.33.1->kaggle-environments) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in c:\\users\\chand\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers>=4.33.1->kaggle-environments) (2023.10.3)\n","Collecting tokenizers<0.15,>=0.14\n","  Using cached tokenizers-0.14.1-cp311-none-win_amd64.whl (2.2 MB)\n","Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\chand\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers>=4.33.1->kaggle-environments) (0.4.0)\n","Requirement already satisfied: tqdm>=4.27 in c:\\users\\chand\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers>=4.33.1->kaggle-environments) (4.66.1)\n","Requirement already satisfied: colorama in c:\\users\\chand\\appdata\\roaming\\python\\python311\\site-packages (from click>=8.1.3->Flask>=1.1.2->kaggle-environments) (0.4.6)\n","Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\chand\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers>=4.33.1->kaggle-environments) (2023.10.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\chand\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from Jinja2>=3.1.2->Flask>=1.1.2->kaggle-environments) (2.1.3)\n","Collecting huggingface-hub<1.0,>=0.16.4\n","  Using cached huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n","Requirement already satisfied: sympy in c:\\users\\chand\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.13->stable-baselines3==2.1.0->kaggle-environments) (1.12)\n","Requirement already satisfied: networkx in c:\\users\\chand\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.13->stable-baselines3==2.1.0->kaggle-environments) (3.2.1)\n","Collecting contourpy>=1.0.1\n","  Using cached contourpy-1.2.0-cp311-cp311-win_amd64.whl (187 kB)\n","Requirement already satisfied: cycler>=0.10 in c:\\users\\chand\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->stable-baselines3==2.1.0->kaggle-environments) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\chand\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->stable-baselines3==2.1.0->kaggle-environments) (4.44.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\chand\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->stable-baselines3==2.1.0->kaggle-environments) (1.4.5)\n","Requirement already satisfied: pillow>=8 in c:\\users\\chand\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->stable-baselines3==2.1.0->kaggle-environments) (10.1.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\chand\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->stable-baselines3==2.1.0->kaggle-environments) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\chand\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib->stable-baselines3==2.1.0->kaggle-environments) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in c:\\users\\chand\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->stable-baselines3==2.1.0->kaggle-environments) (2023.3.post1)\n","Requirement already satisfied: tzdata>=2022.1 in c:\\users\\chand\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->stable-baselines3==2.1.0->kaggle-environments) (2023.3)\n","Requirement already satisfied: six>=1.5 in c:\\users\\chand\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3==2.1.0->kaggle-environments) (1.16.0)\n","Requirement already satisfied: mpmath>=0.19 in c:\\users\\chand\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch>=1.13->stable-baselines3==2.1.0->kaggle-environments) (1.3.0)\n","Installing collected packages: vec-noise, scipy, requests, referencing, Jinja2, gymnasium, contourpy, torch, shimmy, pettingzoo, pandas, matplotlib, jsonschema-specifications, huggingface-hub, Flask, tokenizers, stable-baselines3, jsonschema, transformers, kaggle-environments\n","  Running setup.py install for vec-noise: started\n","  Running setup.py install for vec-noise: finished with status 'error'\n"]},{"name":"stderr","output_type":"stream","text":["  DEPRECATION: vec-noise is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\n","  error: subprocess-exited-with-error\n","  \n","  × Running setup.py install for vec-noise did not run successfully.\n","  │ exit code: 1\n","  ╰─> [16 lines of output]\n","      running install\n","      C:\\Users\\chand\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\command\\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n","        warnings.warn(\n","      running build\n","      running build_py\n","      creating build\n","      creating build\\lib.win-amd64-cpython-311\n","      creating build\\lib.win-amd64-cpython-311\\vec_noise\n","      copying perlin.py -> build\\lib.win-amd64-cpython-311\\vec_noise\n","      copying shader.py -> build\\lib.win-amd64-cpython-311\\vec_noise\n","      copying shader_noise.py -> build\\lib.win-amd64-cpython-311\\vec_noise\n","      copying test.py -> build\\lib.win-amd64-cpython-311\\vec_noise\n","      copying __init__.py -> build\\lib.win-amd64-cpython-311\\vec_noise\n","      running build_ext\n","      building 'vec_noise._simplex' extension\n","      error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n","      [end of output]\n","  \n","  note: This error originates from a subprocess, and is likely not a problem with pip.\n","error: legacy-install-failure\n","\n","× Encountered error while trying to install package.\n","╰─> vec-noise\n","\n","note: This is an issue with the package mentioned above, not pip.\n","hint: See above for output from the failure.\n","\n","[notice] A new release of pip available: 22.3.1 -> 23.3.1\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n"]}],"source":["!pip install kaggle-environments --upgrade"]},{"cell_type":"code","execution_count":18,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-11-03T09:55:59.501536Z","iopub.status.busy":"2023-11-03T09:55:59.501145Z","iopub.status.idle":"2023-11-03T09:55:59.578025Z","shell.execute_reply":"2023-11-03T09:55:59.574051Z","shell.execute_reply.started":"2023-11-03T09:55:59.501489Z"},"id":"70E_TWot-Y8A","outputId":"3c4a5058-c60a-459d-812d-2f4df5a2a6a8","trusted":true},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'pandas'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[1;32mIn[18], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m__future__\u001b[39;00m \u001b[39mimport\u001b[39;00m print_function\n\u001b[0;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m \u001b[39m# linear algebra\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m \u001b[39m# data processing, CSV file I/O (e.g. pd.read_csv)\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"]}],"source":["from __future__ import absolute_import\n","from __future__ import division\n","from __future__ import print_function\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import os\n","import sys\n","import PIL.Image\n","\n","import tensorflow as tf\n","import logging\n","\n","from sklearn import preprocessing\n","import random\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","from kaggle_environments import evaluate, make\n","from kaggle_environments.envs.halite.helpers import *\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-11-03T09:55:59.579057Z","iopub.status.idle":"2023-11-03T09:55:59.579584Z"},"id":"X9x4rOBK-Y8O","trusted":true},"outputs":[{"ename":"NameError","evalue":"name 'tf' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m seed\u001b[39m=\u001b[39m\u001b[39m123\u001b[39m\n\u001b[1;32m----> 2\u001b[0m tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mset_random_seed(seed)\n\u001b[0;32m      3\u001b[0m session_conf \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mConfigProto(intra_op_parallelism_threads\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, inter_op_parallelism_threads\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m      4\u001b[0m sess \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mSession(graph\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mget_default_graph(), config\u001b[39m=\u001b[39msession_conf)\n","\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"]}],"source":["seed=123\n","tf.compat.v1.set_random_seed(seed)\n","session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","tf.compat.v1.keras.backend.set_session(sess)\n","logging.disable(sys.maxsize)\n","global ship_"]},{"cell_type":"markdown","metadata":{},"source":["## Analyzing the environment\n","Lets take a tour of our environment and its settings first."]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.status.busy":"2023-11-03T09:55:59.580571Z","iopub.status.idle":"2023-11-03T09:55:59.581154Z"},"id":"sV_2Kxnn-Y8c","outputId":"a5f04408-7988-4da5-890b-ad8aa45861ba","trusted":true},"outputs":[{"ename":"NameError","evalue":"name 'make' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m env \u001b[39m=\u001b[39m make(\u001b[39m\"\u001b[39m\u001b[39mhalite\u001b[39m\u001b[39m\"\u001b[39m, debug\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      2\u001b[0m env\u001b[39m.\u001b[39mrun([\u001b[39m\"\u001b[39m\u001b[39mrandom\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m      3\u001b[0m env\u001b[39m.\u001b[39mrender(mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mipython\u001b[39m\u001b[39m\"\u001b[39m,width\u001b[39m=\u001b[39m\u001b[39m800\u001b[39m, height\u001b[39m=\u001b[39m\u001b[39m600\u001b[39m)\n","\u001b[1;31mNameError\u001b[0m: name 'make' is not defined"]}],"source":["env = make(\"halite\", debug=True)\n","env.run([\"random\"])\n","env.render(mode=\"ipython\",width=800, height=600)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-11-03T09:55:59.582368Z","iopub.status.idle":"2023-11-03T09:55:59.582919Z"},"id":"2bdT3Gpi-Y8o","outputId":"9599cb00-5ac7-436c-bd48-c3dfe9e32e86","trusted":true},"outputs":[],"source":["env.configuration"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-11-03T09:55:59.583993Z","iopub.status.idle":"2023-11-03T09:55:59.584475Z"},"id":"89pvWtr2-Y8w","outputId":"963a0fd9-366f-4bd0-a55f-389154f8175e","trusted":true},"outputs":[],"source":["env.specification"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-11-03T09:55:59.585476Z","iopub.status.idle":"2023-11-03T09:55:59.586062Z"},"id":"bkZuJWY4-Y85","outputId":"dc9df746-28a1-4a62-8174-3b08b6879282","trusted":true},"outputs":[],"source":["env.specification.reward"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-11-03T09:55:59.587132Z","iopub.status.idle":"2023-11-03T09:55:59.587644Z"},"id":"SXP9fHLl-Y9D","outputId":"b68bba2e-2a55-441d-bb17-d1b6e2fd4761","trusted":true},"outputs":[],"source":["env.specification.action"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-11-03T09:55:59.588656Z","iopub.status.idle":"2023-11-03T09:55:59.589163Z"},"id":"4YE4r_pI-Y9J","outputId":"7bbdfcec-bae7-482a-98d6-53a1ad73d510","trusted":true},"outputs":[],"source":["env.specification.observation"]},{"cell_type":"markdown","metadata":{},"source":["## The game begins\n","So lets train our model with respect to random actions and see what happens..."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-11-03T09:55:59.590313Z","iopub.status.idle":"2023-11-03T09:55:59.590794Z"},"id":"UZRli1_T-Y9Q","trusted":true},"outputs":[],"source":["def getDirTo(fromPos, toPos, size):\n","    fromX, fromY = divmod(fromPos[0],size), divmod(fromPos[1],size)\n","    toX, toY = divmod(toPos[0],size), divmod(toPos[1],size)\n","    if fromY < toY: return ShipAction.NORTH\n","    if fromY > toY: return ShipAction.SOUTH\n","    if fromX < toX: return ShipAction.EAST\n","    if fromX > toX: return ShipAction.WEST\n","\n","# Directions a ship can move\n","directions = [ShipAction.NORTH, ShipAction.EAST, ShipAction.SOUTH, ShipAction.WEST]\n","\n","# Will keep track of whether a ship is collecting halite or carrying cargo to a shipyard\n","ship_states = {}\n","\n","# Returns the commands we send to our ships and shipyards\n","def simple_agent(obs, config):\n","    size = config.size\n","    board = Board(obs, config)\n","    me = board.current_player\n","    # If there are no ships, use first shipyard to spawn a ship.\n","    if len(me.ships) == 0 and len(me.shipyards) > 0:\n","        me.shipyards[0].next_action = ShipyardAction.SPAWN\n","\n","    # If there are no shipyards, convert first ship into shipyard.\n","    if len(me.shipyards) == 0 and len(me.ships) > 0:\n","        me.ships[0].next_action = ShipAction.CONVERT\n","    \n","    for ship in me.ships:\n","        if ship.next_action == None:\n","            \n","            ### Part 1: Set the ship's state \n","            if ship.halite < 200: # If cargo is too low, collect halite\n","                ship_states[ship.id] = \"COLLECT\"\n","            if ship.halite > 500: # If cargo gets very big, deposit halite\n","                ship_states[ship.id] = \"DEPOSIT\"\n","                \n","            ### Part 2: Use the ship's state to select an action\n","            if ship_states[ship.id] == \"COLLECT\":\n","                # If halite at current location running low, \n","                # move to the adjacent square containing the most halite\n","                if ship.cell.halite < 100:\n","                    neighbors = [ship.cell.north.halite, ship.cell.east.halite, \n","                                 ship.cell.south.halite, ship.cell.west.halite]\n","                    best = max(range(len(neighbors)), key=neighbors.__getitem__)\n","                    ship.next_action = directions[best]\n","            if ship_states[ship.id] == \"DEPOSIT\":\n","                # Move towards shipyard to deposit cargo\n","                direction = getDirTo(ship.position, me.shipyards[0].position, size)\n","                if direction: ship.next_action = direction\n","                \n","    return me.next_actions"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-11-03T09:55:59.591884Z","iopub.status.idle":"2023-11-03T09:55:59.592379Z"},"id":"uJMYO9VZ-Y9Y","outputId":"48bd7a63-13d5-4163-bb79-51d866d00095","trusted":true},"outputs":[],"source":["trainer = env.train([None, \"random\"])\n","observation = trainer.reset()\n","while not env.done:\n","    my_action = simple_agent(observation, env.configuration)\n","    print(\"My Action\", my_action)\n","    observation = trainer.step(my_action)[0]\n","    print(\"Reward gained\",observation.players[0][0])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-11-03T09:55:59.593435Z","iopub.status.idle":"2023-11-03T09:55:59.593949Z"},"id":"gQeSpK_s-Y9g","outputId":"6ef704d6-3525-4068-80f0-eb362bbbda2e","trusted":true},"outputs":[],"source":["env.render(mode=\"ipython\",width=800, height=600)"]},{"cell_type":"markdown","metadata":{},"source":["## Our objective\n","As you could see from the results that the yellow ships on the left-hand side show almost no movement whereas the red ships on the right-hand side show some smart movements to collect halite, deposit them in the shipyard and spawn accordingly. Our objective would be to train the yellow ships through reinforcement learning and program an AI model which could perform the given task in the most efficient path possible."]},{"cell_type":"markdown","metadata":{},"source":["## The Obstacles\n","I am not a mastermind with reinforcement learning. So, I faced some problems which I would discuss now and also how I tried to solve some of them.\n","* Controlling only one ship - I have made this program in a way that the agent could only control one ship at a time. Which indeed means I have disabled the respawning of multiple ships.\n","* 5 Moves Game - Due to the first problem I have made this game limited up to the prediction of 4 direction(East, West, North, South) and predicting when to transform from ship to ship-yard. I have removed the SPAWN feature from prediction because I still had not discovered any way to control multiple ships through Actor-Critic agent.\n","* Deposit to the last shipyard - If there is no ship, the ship would spawn from the most recent shipyard developed and would deposit halites to the most recent shipyard developed. It would have been better if I would have discovered a way to calculate the nearest shipyard for deposition of collected halites. \n","![chess](https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Ftse1.mm.bing.net%2Fth%3Fid%3DOIP.GTWpPAXsc0-kjWXyEqpGywHaEt%26pid%3DApi&f=1)"]},{"cell_type":"markdown","metadata":{},"source":["## The Actor-Critic model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-11-03T09:55:59.595161Z","iopub.status.idle":"2023-11-03T09:55:59.595639Z"},"id":"HCPI5mpD-Y-F","trusted":true},"outputs":[],"source":["def ActorModel(num_actions,in_):\n","    common = tf.keras.layers.Dense(128, activation='tanh')(in_)\n","    common = tf.keras.layers.Dense(32, activation='tanh')(common)\n","    common = tf.keras.layers.Dense(num_actions, activation='softmax')(common)\n","    \n","    return common"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-11-03T09:55:59.596686Z","iopub.status.idle":"2023-11-03T09:55:59.597307Z"},"id":"LAax9a8q-Y-L","trusted":true},"outputs":[],"source":["def CriticModel(in_):\n","    common = tf.keras.layers.Dense(128)(in_)\n","    common = tf.keras.layers.ReLU()(common)\n","    common = tf.keras.layers.Dense(32)(common)\n","    common = tf.keras.layers.ReLU()(common)\n","    common = tf.keras.layers.Dense(1)(common)\n","    \n","    return common"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-11-03T09:55:59.598333Z","iopub.status.idle":"2023-11-03T09:55:59.598886Z"},"id":"ODputeIs-Y-T","outputId":"7b620300-daaf-4699-eb97-d8d1bd52dbec","trusted":true},"outputs":[],"source":["input_ = tf.keras.layers.Input(shape=[441,])\n","model = tf.keras.Model(inputs=input_, outputs=[ActorModel(5,input_),CriticModel(input_)])\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-11-03T09:55:59.600226Z","iopub.status.idle":"2023-11-03T09:55:59.600841Z"},"id":"G8a9NRpJ-Y-Z","trusted":true},"outputs":[],"source":["optimizer = tf.keras.optimizers.Adam(lr=7e-4)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-11-03T09:55:59.601943Z","iopub.status.idle":"2023-11-03T09:55:59.602607Z"},"id":"t_r9VCHQ-Y-e","trusted":true},"outputs":[],"source":["huber_loss = tf.keras.losses.Huber()\n","action_probs_history = []\n","critic_value_history = []\n","rewards_history = []\n","running_reward = 0\n","episode_count = 0\n","num_actions = 5\n","eps = np.finfo(np.float32).eps.item()\n","gamma = 0.99  # Discount factor for past rewards\n","env = make(\"halite\", debug=True)\n","trainer = env.train([None,\"random\"])"]},{"cell_type":"markdown","metadata":{},"source":["## Encoding our moves"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-11-03T09:55:59.603647Z","iopub.status.idle":"2023-11-03T09:55:59.604199Z"},"id":"tOB7Y9Di-Y-i","outputId":"0ad76f4c-83de-4672-b38e-ce702cd5d851","trusted":true},"outputs":[],"source":["le = preprocessing.LabelEncoder()\n","label_encoded = le.fit_transform(['NORTH', 'SOUTH', 'EAST', 'WEST', 'CONVERT'])\n","label_encoded"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-11-03T09:55:59.605472Z","iopub.status.idle":"2023-11-03T09:55:59.606077Z"},"id":"hspjmUQb-Y-o","trusted":true},"outputs":[],"source":["def getDirTo(fromPos, toPos, size):\n","    fromX, fromY = divmod(fromPos[0],size), divmod(fromPos[1],size)\n","    toX, toY = divmod(toPos[0],size), divmod(toPos[1],size)\n","    if fromY < toY: return ShipAction.NORTH\n","    if fromY > toY: return ShipAction.SOUTH\n","    if fromX < toX: return ShipAction.EAST\n","    if fromX > toX: return ShipAction.WEST\n","\n","# Directions a ship can move\n","directions = [ShipAction.NORTH, ShipAction.EAST, ShipAction.SOUTH, ShipAction.WEST]\n","   \n","def decodeDir(act_):\n","    if act_ == 'NORTH':return directions[0]\n","    if act_ == 'EAST':return directions[1]\n","    if act_ == 'SOUTH':return directions[2]\n","    if act_ == 'WEST':return directions[3]\n","    \n","# Will keep track of whether a ship is collecting halite or carrying cargo to a shipyard\n","ship_states = {}\n","ship_ = 0\n","def update_L1():\n","    ship_+=1\n","# Returns the commands we send to our ships and shipyards\n","def advanced_agent(obs, config, action):\n","    size = config.size\n","    board = Board(obs, config)\n","    me = board.current_player \n","    act = le.inverse_transform([action])[0]\n","    global ship_\n","    \n","   # If there are no ships, use first shipyard to spawn a ship.\n","    if len(me.ships) == 0 and len(me.shipyards) > 0:\n","        me.shipyards[ship_-1].next_action = ShipyardAction.SPAWN\n","\n","    # If there are no shipyards, convert first ship into shipyard.\n","    if len(me.shipyards) == 0 and len(me.ships) > 0 and ship_==0:\n","        me.ships[0].next_action = ShipAction.CONVERT   \n","    try: \n","        if act=='CONVERT':\n","            me.ships[0].next_action = ShipAction.CONVERT\n","            update_L1()\n","            if len(me.ships)==0 and len(me.shipyards) > 0:\n","                me.shipyards[ship_-1].next_action = ShipyardAction.SPAWN\n","        if me.ships[0].halite < 200:\n","            ship_states[me.ships[0].id] = 'COLLECT'\n","        if me.ships[0].halite > 800:\n","            ship_states[me.ships[0].id] = 'DEPOSIT' \n","\n","        if ship_states[me.ships[0].id] == 'COLLECT': \n","            if me.ships[0].cell.halite < 100:\n","                me.ships[0].next_action = decodeDir(act)\n","        if ship_states[me.ships[0].id] == 'DEPOSIT':\n","            # Move towards shipyard to deposit cargo\n","            direction = getDirTo(me.ships[0].position, me.shipyards[ship_-1].position, size)\n","            if direction: me.ships[0].next_action = direction\n","    except:\n","        pass\n","                \n","    return me.next_actions"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-11-03T09:55:59.607430Z","iopub.status.idle":"2023-11-03T09:55:59.607996Z"},"id":"VYPUuqwa-Y-s","outputId":"15bcf4d9-f7a1-4dfd-eae9-e01c66d581cd","trusted":true},"outputs":[],"source":["while not env.done:    \n","    state = trainer.reset()\n","    episode_reward = 0\n","    with tf.GradientTape() as tape:\n","        for timestep in range(1,env.configuration.episodeSteps+200):\n","            # of the agent in a pop up window.\n","            state_ = tf.convert_to_tensor(state.halite)\n","            state_ = tf.expand_dims(state_, 0)\n","            # Predict action probabilities and estimated future rewards\n","            # from environment state\n","            action_probs, critic_value = model(state_)\n","            critic_value_history.append(critic_value[0, 0])\n","            \n","            # Sample action from action probability distribution\n","            action = np.random.choice(num_actions, p=np.squeeze(action_probs))\n","            action_probs_history.append(tf.math.log(action_probs[0, action]))\n","            \n","            # Apply the sampled action in our environment\n","            action = advanced_agent(state, env.configuration, action)\n","            state = trainer.step(action)[0]\n","            gain=state.players[0][0]/5000\n","            rewards_history.append(gain)\n","            episode_reward += gain\n","            \n","            if env.done:\n","                state = trainer.reset() \n","        # Update running reward to check condition for solving\n","        running_reward = 0.05 * episode_reward + (1 - 0.05) * running_reward\n","\n","        # Calculate expected value from rewards\n","        # - At each timestep what was the total reward received after that timestep\n","        # - Rewards in the past are discounted by multiplying them with gamma\n","        # - These are the labels for our critic\n","        returns = []\n","        discounted_sum = 0\n","        for r in rewards_history[::-1]:\n","            discounted_sum = r + gamma * discounted_sum\n","            returns.insert(0, discounted_sum)\n","        # Normalize\n","        returns = np.array(returns)\n","        returns = (returns - np.mean(returns)) / (np.std(returns) + eps)\n","        returns = returns.tolist()\n","        # Calculating loss values to update our network\n","        history = zip(action_probs_history, critic_value_history, returns)\n","        actor_losses = []\n","        critic_losses = []\n","        for log_prob, value, ret in history:\n","            # At this point in history, the critic estimated that we would get a\n","            # total reward = `value` in the future. We took an action with log probability\n","            # of `log_prob` and ended up recieving a total reward = `ret`.\n","            # The actor must be updated so that it predicts an action that leads to\n","            # high rewards (compared to critic's estimate) with high probability.\n","            diff = ret - value\n","            actor_losses.append(-log_prob * diff)  # actor loss\n","\n","            # The critic must be updated so that it predicts a better estimate of\n","            # the future rewards.\n","            critic_losses.append(\n","                huber_loss(tf.expand_dims(value, 0), tf.expand_dims(ret, 0))\n","            )\n","        # Backpropagation\n","        loss_value = sum(actor_losses) + sum(critic_losses)\n","        grads = tape.gradient(loss_value, model.trainable_variables)\n","        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n","        \n","        # Clear the loss and reward history\n","        action_probs_history.clear()\n","        critic_value_history.clear()\n","        rewards_history.clear()\n","        \n","    # Log details\n","    episode_count += 1\n","    if episode_count % 10 == 0:\n","        template = \"running reward: {:.2f} at episode {}\"\n","        print(template.format(running_reward, episode_count))\n","\n","    if running_reward > 550:  # Condition to consider the task solved\n","        print(\"Solved at episode {}!\".format(episode_count))\n","        break"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-11-03T09:55:59.609157Z","iopub.status.idle":"2023-11-03T09:55:59.609726Z"},"id":"2EfsKArk-Y-1","trusted":true},"outputs":[],"source":["while not env.done:\n","    state_ = tf.convert_to_tensor(state.halite)\n","    state_ = tf.expand_dims(state_, 0)\n","    action_probs, critic_value = model(state_)\n","    critic_value_history.append(critic_value[0, 0])\n","    action = np.random.choice(num_actions, p=np.squeeze(action_probs))\n","    action_probs_history.append(tf.math.log(action_probs[0, action]))\n","    action = advanced_agent(state, env.configuration, action)\n","    state = trainer.step(action)[0]"]},{"cell_type":"markdown","metadata":{},"source":["## Results\n","The Yellow ships and shipyards are controlled by our trained actor-critic model and the red ship and shipyards are trained against the random predicting agent."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-11-03T09:55:59.611032Z","iopub.status.idle":"2023-11-03T09:55:59.611594Z"},"id":"Q5DD5b6v-Y-8","outputId":"c4422de4-3de6-4729-d75a-6b5ce72a24e5","trusted":true},"outputs":[],"source":["env.render(mode=\"ipython\",width=800, height=600)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":4}
